{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2423aa8c-1451-4d69-a534-a88412009829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set up the Hugging Face Hub API token\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b1be1f-701d-4d81-abc0-5cf2fb083ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "/home/fish/anaconda3/envs/jusjus/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/fish/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the repository ID for the Gemma 2b model\n",
    "repo_id = \"google/gemma-2b-it\"\n",
    "\n",
    "# Set up a Hugging Face Endpoint for Gemma 2b model\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, max_length=1024, temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06bd18b-e761-4061-bcbe-d2e04a11d43a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Customised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edcb8eda-1cf1-4f45-9d92-bb8c83c2ba5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "df = pd.read_excel(\"/home/fish/Documents/optymize.xlsx\")\n",
    "data_list = df.values.ravel().tolist()\n",
    "document_list = []\n",
    "\n",
    "# Convert each string to a Document object\n",
    "for content in data_list:\n",
    "    document = Document(content=content, page_content=content)\n",
    "    document_list.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684dcdab-1690-41e4-a864-a756df791545",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 184, which is longer than the specified 100\n",
      "Created a chunk of size 121, which is longer than the specified 100\n",
      "Created a chunk of size 253, which is longer than the specified 100\n",
      "Created a chunk of size 113, which is longer than the specified 100\n",
      "Created a chunk of size 205, which is longer than the specified 100\n",
      "Created a chunk of size 139, which is longer than the specified 100\n",
      "Created a chunk of size 455, which is longer than the specified 100\n",
      "Created a chunk of size 408, which is longer than the specified 100\n",
      "Created a chunk of size 635, which is longer than the specified 100\n",
      "Created a chunk of size 868, which is longer than the specified 100\n",
      "Created a chunk of size 606, which is longer than the specified 100\n",
      "Created a chunk of size 350, which is longer than the specified 100\n",
      "Created a chunk of size 331, which is longer than the specified 100\n",
      "Created a chunk of size 404, which is longer than the specified 100\n",
      "Created a chunk of size 416, which is longer than the specified 100\n",
      "Created a chunk of size 330, which is longer than the specified 100\n",
      "Created a chunk of size 1257, which is longer than the specified 100\n",
      "Created a chunk of size 533, which is longer than the specified 100\n",
      "Created a chunk of size 431, which is longer than the specified 100\n",
      "Created a chunk of size 356, which is longer than the specified 100\n",
      "Created a chunk of size 458, which is longer than the specified 100\n",
      "Created a chunk of size 320, which is longer than the specified 100\n",
      "Created a chunk of size 140, which is longer than the specified 100\n",
      "Created a chunk of size 249, which is longer than the specified 100\n",
      "Created a chunk of size 331, which is longer than the specified 100\n",
      "Created a chunk of size 225, which is longer than the specified 100\n",
      "Created a chunk of size 174, which is longer than the specified 100\n",
      "Created a chunk of size 320, which is longer than the specified 100\n",
      "Created a chunk of size 222, which is longer than the specified 100\n",
      "Created a chunk of size 256, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(document_list)\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e962be5-9aa6-4e0e-b926-c9ff3243fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={'k': 4, 'fetch_k': 20})\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acfe97ea-c5b7-463a-9f6e-22021e83bcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Optymize is a protocol that allows users to lend their tokens to Optymize and earn returns in the form of OPZ tokens.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is Optymize?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "facee166-6a6e-4c25-966b-779db193eb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' You can deposit coins on Optymize by staking them into the Vault or Liquidity Pool.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"how can i deposite coin on Optymize?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f93cc78-334a-4a59-9907-ab268187c1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Twitter handle for Optymize is @Optymize_xyz.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is Optymize's twitter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68bf33e6-c1f7-4659-bf8b-b4ed26baa663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' gOPZ tokens are a reward system for long term users of Optymize. They can be earned by staking OPZ tokens with the platform.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is gOPZ tokens?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aaf1fd3-37a9-49fe-86cc-270dc8faa085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Optymize tokenomics is a system that allows users to stake their tokens and earn returns in the form of OPZ tokens.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is Optymize tokenomics?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "139f8171-c791-4f82-ae2c-03f62d664ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Optymize details tokenomics by selecting the tokens to be pooled together based on a combination of factors including TVL, risk ranking, audit scores, market demand and community feedback.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is Optymize details tokenomics?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edad3da1-9a78-40c4-8137-4263d7dbb5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Optymize Vault model creates vaults for depositors to stake their tokens to earn yield and mitigate Security Incident risk together. The tokens staked will be pooled together and all depositors will share the losses (if any) with one another proportionately when a Security Incident happens.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Optymize Vault Model – How does it works?, detail explaination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbdcd63b-b52c-4e55-978e-00c4a80a6699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Optymize Vault Model is a transparent investment strategy that uses various yield farms to maximize returns.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Optymize Vault Model – How does it works?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jusjus",
   "language": "python",
   "name": "jusjus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
